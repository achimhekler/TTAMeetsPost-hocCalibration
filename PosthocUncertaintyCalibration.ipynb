{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873fd857-27ba-4f5a-ade0-e853ee717c7f",
   "metadata": {},
   "source": [
    "# Post-hoc Uncertainty Calibration by Test-Time Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14873a76-b27b-4773-b936-220253c09dd1",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3370f9-f4ca-48b9-96cd-57a0e61dac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as trn\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from scipy import optimize\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import ssl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f5b46-42bf-46c9-8ab2-662811b75248",
   "metadata": {},
   "source": [
    "#### Set Seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1bdd0-e840-445a-b48b-0e384951d278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(dls,x=42): \n",
    "    random.seed(x)\n",
    "    dls.rng.seed(x) \n",
    "    np.random.seed(x)\n",
    "    torch.manual_seed(x)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4da3f4-98cc-42c9-a761-49849623e5a1",
   "metadata": {},
   "source": [
    "#### Specification of parser for experimental parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50670a7-7614-42b2-bdb0-a34e53a32d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model\")\n",
    "    parser.add_argument(\"--dataset\")\n",
    "    parser.add_argument(\"--batchsize\", type=int)\n",
    "    parser.add_argument(\"--n_bins\", type=int)\n",
    "    parser.add_argument(\"--mult_val\", type=int) \n",
    "    parser.add_argument(\"--mult_test\", type=int)\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575954d5-3a17-4179-8da9-10c9d83f5b2f",
   "metadata": {},
   "source": [
    "#### Load model and identify metadata from filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a79a1f1-dc9f-4ddd-a6e5-6d0de1b42138",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(\"models/\" + trained_model)\n",
    "metadata = trained_model.split(\"_\")\n",
    "\n",
    "dataset = metadata[0] \n",
    "model = metadata[1]\n",
    "imgSize = int(metadata[-1].split(\".\")[0])\n",
    "\n",
    "# number of classes\n",
    "if dataset == \"cifar10\":\n",
    "    n_classes = 10\n",
    "if dataset == \"cifar100\":\n",
    "    n_classes = 100\n",
    "if dataset == \"skin\":\n",
    "    n_classes = 2\n",
    "\n",
    "result_fname = dataset + model + \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e94de0-c4cd-4669-98ce-cc89f9c834da",
   "metadata": {},
   "source": [
    "#### Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd158345-9125-496d-af17-d7d905ee4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"cifar10\":\n",
    "    df_train = pd.read_csv(path1 + \"data/cifar10/cifar10_TrainValidSplit.csv\")\n",
    "    df_train[\"fn\"] = [\"data/\" + x for x in df_train[\"fn\"].values]\n",
    "if dataset == \"cifar100\":\n",
    "    df_train = pd.read_csv(+ \"data/cifar100/cifar100_TrainValidSplit.csv\")\n",
    "    df_train[\"fn\"] = [\"data/\" + x for x in df_train[\"fn\"].values]\n",
    "if dataset == \"skin\":\n",
    "    df_train = pd.read_csv(path1 + \"data/skin_new/skin_TrainValidSplit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031c42a-5d88-4ae0-9e9e-501ac2ec89aa",
   "metadata": {},
   "source": [
    "#### Definition of hook for  storing the logits of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7615d8-6f84-4b5c-bc59-e22c6a3c3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregatingHook(Hook):\n",
    "    '''aggregate hook outputs in 'stored' in case inference is carried out over the entire dataset in a loop'''\n",
    "    def __init__(self, m, hook_func, is_forward=True, detach=True, cpu=False, gather=False):\n",
    "        super().__init__(m, hook_func, is_forward, detach, cpu, gather)\n",
    "        self.stored = list()\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        \"Applies `hook_func` to `module`, `input`, `output`.\"\n",
    "        if self.detach:\n",
    "            input,output = to_detach(input, cpu=self.cpu, gather=self.gather),to_detach(output, cpu=self.cpu, gather=self.gather)\n",
    "        self.stored.append(self.hook_func(module, input, output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea98b4-4688-4814-b65c-0bbf0dc80d2e",
   "metadata": {},
   "source": [
    "### Methods for Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec37cc-0ec9-4cdf-9727-49b053361075",
   "metadata": {},
   "source": [
    "#### Calculation of ECE and MCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76453ff2-2018-4402-ba05-fe961e3ff16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(preds, targs, num_bins):\n",
    "    \"\"\" Calculation of calibration\n",
    "    \n",
    "    References:\n",
    "    https://arxiv.org/abs/1706.04599\n",
    "    \n",
    "    Args:\n",
    "      targs: true classes (type: TensorCategory, size [number of samples])\n",
    "      preds: confidence scores (type: Tensor, size [number of samples, number of classes]\n",
    "      num_bins: number of bins\n",
    "      \n",
    "    Returns:\n",
    "      cal: a dictionary\n",
    "        {reliability_diag: reliability diagram,\n",
    "         ece: Expected Calibration Error,\n",
    "         mce: Maximum Calibration Error}\n",
    "    \"\"\"\n",
    "    class_preds = preds.argmax(dim=-1)\n",
    "    # and the confidence (probability) associated with it.\n",
    "    max_value = torch.max(preds, dim=1)\n",
    "    conf = max_value.values\n",
    "    conf = np.clip(conf, 1e-6, 1-1e-6)\n",
    "    #Storage\n",
    "    acc_tab = np.zeros(num_bins) #empirical (true) confidence\n",
    "    mean_conf = np.zeros(num_bins) #predicted confidence\n",
    "    nb_items_bin = np.zeros(num_bins) #number of items in the bins\n",
    "    tau_tab = np.linspace(0,1,num_bins+1) #limits of the bins\n",
    "\n",
    "    for i in np.arange(num_bins): #iterate over the bins\n",
    "        sec = (tau_tab[i + 1] > conf) & (conf >= tau_tab[i])\n",
    "        nb_items_bin[i] = sum(sec) #number of samples in the bin\n",
    "        # select the predicted classes, and the true classes\n",
    "        class_preds_sec, targs_sec = class_preds[sec], targs[sec]\n",
    "        # average of the predicted max probabilities\n",
    "        mean_conf[i] = torch.mean(conf[sec]) if nb_items_bin[i] > 0 else np.nan\n",
    "        # compute the empirical confidence\n",
    "        acc_tab[i] = np.mean(np.array(class_preds_sec) == np.array(targs_sec)) if nb_items_bin[i] > 0 else np.nan\n",
    "    # check that every sample in the test set is included into the calculation of the ECE\n",
    "    try:\n",
    "        assert (sum(nb_items_bin) == len(targs))\n",
    "    except AssertionError:\n",
    "        print(\"Error: Not all samples are included into the calculation of ECE\")\n",
    "\n",
    "    #Cleaning\n",
    "    mean_conf = mean_conf[nb_items_bin > 0]\n",
    "    acc_tab = acc_tab[nb_items_bin > 0]\n",
    "    nb_items_bin = nb_items_bin[nb_items_bin > 0]\n",
    "    \n",
    "    #Reliability diagram\n",
    "    reliability_diag = (mean_conf, acc_tab)\n",
    "    #Expected Calibration Error\n",
    "    ece = np.average(\n",
    "        np.absolute(mean_conf - acc_tab),\n",
    "        weights=nb_items_bin.astype(float) / np.sum(nb_items_bin))\n",
    "    #Maximum Calibration Error\n",
    "    mce = np.max(np.absolute(mean_conf - acc_tab))\n",
    "    #Saving\n",
    "    cal = {'reliability_diag': reliability_diag,\n",
    "           'ece': ece,\n",
    "           'mce': mce}\n",
    "    return cal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636878f-e315-4ddc-a1e2-8e472c38f6c9",
   "metadata": {},
   "source": [
    "#### Calculation of Brier score and negative log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae4041-eb96-42ea-b4c9-62a5f6efcb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_scores(probs, targets, nbin=30, fn=abs):\n",
    "    \"\"\"\n",
    "    Calculate accuracy, ECE, negative log-likelihood, Brier score\n",
    "    :param probs: (numpy.array) predictions of dimension N x C where N is number of example, C is classes\n",
    "    :param targets: (numpy.array) targets of dimension N\n",
    "    :param nbin: (int) number of bins for calculating ECE\n",
    "    :param fn: (function) function to transform conf - acc to fn(conf - acc) for ECE, sECE\n",
    "    :return: tuple containing Accuracy, ECE, NLL, Brier\n",
    "    \"\"\"\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    correct = (preds == targets)\n",
    "    class_probs = np.take_along_axis(probs, targets.astype(np.uint8)[:, None], axis=1)\n",
    "    nll = np.mean(-np.log(class_probs))\n",
    "    maxprobs = np.max(probs, axis=-1)\n",
    "    one_hot = np.eye(probs.shape[1])[targets.astype(np.int32)]\n",
    "    brier_score = np.mean(np.sum((probs - one_hot) ** 2, axis=1))\n",
    "    return nll, brier_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65626bcc-5954-4e49-b8d8-0078bdd5529a",
   "metadata": {},
   "source": [
    "#### Implementation of baseline methods (TS, IR, IRM, ETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08becf-5209-4a72-88b9-61904967c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_t(t, *args):\n",
    "## find optimal temperature with MSE loss function\n",
    "\n",
    "    logit, label = args\n",
    "    logit = logit/t\n",
    "    n = np.sum(np.exp(logit),1)  \n",
    "    p = np.exp(logit)/n[:,None]\n",
    "    mse = np.mean((p-label)**2)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def ll_t(t, *args):\n",
    "## find optimal temperature with Cross-Entropy loss function\n",
    "\n",
    "    logit, label = args\n",
    "    logit = logit/t\n",
    "    n = np.sum(np.exp(logit),1)  \n",
    "    p = np.clip(np.exp(logit)/n[:,None],1e-20,1-1e-20)\n",
    "    N = p.shape[0]\n",
    "    ce = -np.sum(label*np.log(p))/N\n",
    "    return ce\n",
    "\n",
    "\n",
    "\n",
    "def mse_w(w, *args):\n",
    "## find optimal weight coefficients with MSE loss function\n",
    "\n",
    "    p0, p1, p2, label = args\n",
    "    p = w[0]*p0+w[1]*p1+w[2]*p2\n",
    "    p = p/np.sum(p,1)[:,None]\n",
    "    mse = np.mean((p-label)**2)   \n",
    "    return mse\n",
    "\n",
    "\n",
    "def ll_w(w, *args):\n",
    "## find optimal weight coefficients with Cros-Entropy loss function\n",
    "\n",
    "    p0, p1, p2, label = args\n",
    "    p = (w[0]*p0+w[1]*p1+w[2]*p2)\n",
    "    N = p.shape[0]\n",
    "    ce = -np.sum(label*np.log(p))/N\n",
    "    return ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9771f9-703c-4f86-819b-743bedb4e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_scaling(logit,label,loss):\n",
    "    bnds = ((0.05, 5.0),)\n",
    "    if loss == 'ce':\n",
    "        t = optimize.minimize(ll_t, 1.0 , args = (logit,label), method='L-BFGS-B', bounds=bnds, tol=1e-12)\n",
    "    if loss == 'mse':\n",
    "        t = optimize.minimize(mse_t, 1.0 , args = (logit,label), method='L-BFGS-B', bounds=bnds, tol=1e-12)\n",
    "    t = t.x\n",
    "    return t\n",
    "\n",
    "def ensemble_scaling(logit,label,loss,t,n_class):\n",
    "\n",
    "    p1 = np.exp(logit)/np.sum(np.exp(logit),1)[:,None]\n",
    "    logit = logit/t\n",
    "    p0 = np.exp(logit)/np.sum(np.exp(logit),1)[:,None]\n",
    "    p2 = np.ones_like(p0)/n_class\n",
    "    \n",
    "\n",
    "    bnds_w = ((0.0, 1.0),(0.0, 1.0),(0.0, 1.0),)\n",
    "    def my_constraint_fun(x): return np.sum(x)-1\n",
    "    constraints = { \"type\":\"eq\", \"fun\":my_constraint_fun,}\n",
    "    if loss == 'ce':\n",
    "        w = optimize.minimize(ll_w, (1.0, 0.0, 0.0) , args = (p0,p1,p2,label), method='SLSQP', constraints = constraints, bounds=bnds_w, tol=1e-12, options={'disp': True})\n",
    "    if loss == 'mse':\n",
    "        w = optimize.minimize(mse_w, (1.0, 0.0, 0.0) , args = (p0,p1,p2,label), method='SLSQP', constraints = constraints, bounds=bnds_w, tol=1e-12, options={'disp': True})\n",
    "    w = w.x\n",
    "    return w\n",
    "\n",
    "def ts_calibrate(logit, label,loss):\n",
    "    t = temperature_scaling(logit,label,loss)\n",
    "    print(\"temperature = \" + str(t))\n",
    "    return t\n",
    "\n",
    "def ts_predict(logit, t):\n",
    "    logit = logit/t\n",
    "    preds_transformed = np.exp(logit)/np.sum(np.exp(logit),1)[:,None] \n",
    "    return torch.from_numpy(preds_transformed)\n",
    "\n",
    "def ets_calibrate(logit, label, n_class, loss):\n",
    "    t = temperature_scaling(logit,label,loss='mse') # loss can change to 'ce'\n",
    "    w = ensemble_scaling(logit,label,'mse',t,n_class)\n",
    "    return(t,w)\n",
    "\n",
    "def ets_predict(logit, t, w, n_class):\n",
    "    p1 = np.exp(logit)/np.sum(np.exp(logit),1)[:,None]\n",
    "    logit = logit/t\n",
    "    p0 = np.exp(logit)/np.sum(np.exp(logit),1)[:,None]\n",
    "    p2 = np.ones_like(p0)/n_class\n",
    "    preds_transformed = w[0]*p0 + w[1]*p1 +w[2]*p2\n",
    "    return torch.from_numpy(preds_transformed)\n",
    "\n",
    "def mir_calibrate(logit,label):\n",
    "    p = np.exp(logit)/np.sum(np.exp(logit),1)[:,None] \n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    y_ = ir.fit_transform(p.flatten(), (label.flatten()))\n",
    "    return ir \n",
    "\n",
    "def mir_predict(logit, ir):\n",
    "    p = np.exp(logit)/np.sum(np.exp(logit),1)[:,None] \n",
    "    yt_ = ir.predict(p.flatten())\n",
    "    preds_transformed = yt_.reshape(logit.shape)+1e-9*p\n",
    "    return torch.from_numpy(preds_transformed)\n",
    "\n",
    "def irova_calibrate(logit,label):\n",
    "    p = np.exp(logit)/np.sum(np.exp(logit),1)[:,None]\n",
    "    list_ir = []\n",
    "    for ii in range(p.shape[1]):\n",
    "        ir = IsotonicRegression(out_of_bounds='clip')\n",
    "        y_ = ir.fit_transform(p[:, ii].astype('double'), label[:, ii].astype('double'))\n",
    "        list_ir.append(ir)\n",
    "    return list_ir\n",
    "\n",
    "def irova_predict(logit, list_ir):\n",
    "    p = np.exp(logit)/np.sum(np.exp(logit),1)[:,None]\n",
    "    for ii in range(p.shape[1]):\n",
    "        ir = list_ir[ii]\n",
    "        p[:, ii] = ir.predict(p[:, ii]) + 1e-9 * p[:, ii]\n",
    "    return torch.from_numpy(p)\n",
    "\n",
    "def irovats_calibrate(logit, label, loss='mse'):\n",
    "    t = ts_calibrate(logit, label, loss=loss)\n",
    "    logit = logit / t\n",
    "    list_ir = irova_calibrate(logit, label)\n",
    "    return (t, list_ir)\n",
    "\n",
    "def irovats_predict(logit,t,list_ir):\n",
    "    logit = logit / t\n",
    "    p = irova_predict(logit, list_ir)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd1f64-1ac7-459f-aa79-1799695110b0",
   "metadata": {},
   "source": [
    "#### Implementation of approach from Tomani et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17043b9-4150-44e0-bb72-d7c8e25223a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(Transform):\n",
    "    \n",
    "    def __init__(self, mean=0., std=1., **kwargs):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def encodes(self, x:TensorImage):\n",
    "        x = x / 255.0\n",
    "        x = x + torch.randn(x.size()).cuda() * self.std + self.mean\n",
    "        x = x * 255.0\n",
    "        x = x.type(torch.ByteTensor).cuda()\n",
    "        x = torch.clip(x,0,255)\n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8141f32-4ed5-49fc-9fd1-0c4c6d505278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(learn, df, imgSize, epsilon = 0.0,bs = 300):\n",
    "    \n",
    "    dblock = createDatablock(imgSize, epsilon)\n",
    "    dls = dblock.dataloaders(df, bs=bs, num_workers=3)\n",
    "    set_seed(dls)\n",
    "    learn.dls = dls\n",
    "    \n",
    "    return learn.validate()[1]\n",
    "\n",
    "def estimateEpsilon(learn, df, imgSize, n_classes, bs = 300):\n",
    "\"\"\" Calculation of epsilons for the given target accuracies \"\"\"    \n",
    "    no_pertubations = 6\n",
    "    epsilon_max = 0.3\n",
    "    epsilon_diff = 0.004\n",
    "    acc = []\n",
    "    epsilons = np.arange(0,epsilon_max, epsilon_diff)\n",
    "    result = []\n",
    "    \n",
    "    min_acc = 1 / float(n_classes)\n",
    "    perturbation_levels = range(no_pertubations)\n",
    "    \n",
    "    max_acc = get_accuracy(learn, df, imgSize, 0.0, 300)\n",
    "    \n",
    "    target_accuracy_list = []\n",
    "    for perturbation_level in perturbation_levels:\n",
    "        target_accuracy_list.append(max_acc - (max_acc - min_acc)  * perturbation_level / (len(perturbation_levels) - 1))\n",
    "    \n",
    "    for i in epsilons:\n",
    "        if  i != 0.0 and acc[-1] <= (min_acc + 0.05):\n",
    "            acc.append(min_acc + 0.05)\n",
    "        else:\n",
    "            acc.append(get_accuracy(learn, df, imgSize, i, bs))\n",
    "            \n",
    "        print(\"For epsilon = \" + str(i) +  \"the achieved accuracy is \" + str(acc[-1]))\n",
    "        \n",
    "            \n",
    "    for target_accuracy in target_accuracy_list:\n",
    "        idx = np.argmin(np.abs(acc-np.ones(len(acc))*(target_accuracy+0.03)))\n",
    "        result.append(epsilons[idx])\n",
    "\n",
    "    return result\n",
    "\n",
    "def getLogitsCVPR(learn, df, imgSize, epsilons, bs = 300):\n",
    "\"\"\" Calculation of logits for the given epsilons\"\"\"\n",
    "\n",
    "    targets = []\n",
    "    \n",
    "    hook = AggregatingHook(\n",
    "                m = learn.model[1][8],\n",
    "                hook_func = lambda m,i,o: o,\n",
    "                cpu = True\n",
    "    )\n",
    "    \n",
    "    for epsilon in epsilons:\n",
    "        \n",
    "        dblock = createDatablock(imgSize, epsilon)\n",
    "        dls = dblock.dataloaders(df, bs=bs, num_workers=3)\n",
    "        set_seed(dls)\n",
    "        learn.dls = dls\n",
    "        \n",
    "        preds, targs = learn.get_preds()\n",
    "        \n",
    "        targets.append(targs)\n",
    "            \n",
    "    logits = torch.cat(hook.stored)\n",
    "    targets = torch.cat(targets,0)\n",
    "    \n",
    "    return (logits,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d6cc5-f2e7-4784-be09-66c3d50be3db",
   "metadata": {},
   "source": [
    "#### Create Datablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5479f1e-4eb3-4805-85d0-8530d9de2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDatablock(imgSize, epsilon = None):\n",
    "    \n",
    "    if epsilon == None:\n",
    "        # Datablock without Gaussian Noise\n",
    "        dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "              get_x=ColReader(\"fn\"),\n",
    "              get_y=ColReader(\"label\"), \n",
    "              splitter=ColSplitter(col=\"valid\"),\n",
    "              item_tfms = [Resize(imgSize)],\n",
    "              batch_tfms = [*aug_transforms(mult = mult_val), Normalize.from_stats(*imagenet_stats)])\n",
    "    \n",
    "    else:\n",
    "        # Datablock with Gaussian Noise\n",
    "        dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "              get_x=ColReader(\"fn\"),\n",
    "              get_y=ColReader(\"label\"), \n",
    "              splitter=ColSplitter(col=\"valid\"),\n",
    "              item_tfms = [Resize(imgSize)],\n",
    "              batch_tfms = [*aug_transforms(mult = mult_val), Normalize.from_stats(*imagenet_stats), GaussianNoise(mean = 0.0, std = epsilon)])\n",
    "    \n",
    "    return dblock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e73b5-d53c-4654-a2c3-7a1809b1b851",
   "metadata": {},
   "source": [
    "### Determination of parameters of post-hoc calibration baseline methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997ce20-4140-47c1-ab6e-18d9630803eb",
   "metadata": {},
   "source": [
    "#### Calculate logits on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4978f40-b585-4adc-b9ff-f1f649e128ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = createDatablock(imgSize)\n",
    "              \n",
    "dls = dblock.dataloaders(df_train, bs=bs, num_workers=3)\n",
    "learn.dls = dls\n",
    "\n",
    "hook = AggregatingHook(\n",
    "    m = learn.model[1][8],\n",
    "    hook_func = lambda m,i,o: o,\n",
    "    cpu = True\n",
    ")\n",
    "\n",
    "preds, targs = learn.get_preds()\n",
    "logits = torch.cat(hook.stored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c92f4-8bc5-4a1c-9a4f-a86efe6c319b",
   "metadata": {},
   "source": [
    "#### Calculate parameters of baseline methods on the original validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77596c-5f27-4db1-a90a-d6a534bc1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "targs_onehot = np.eye(n_classes)[targs.numpy()].astype(int)\n",
    "temperature = ts_calibrate(logits.numpy(), targs_onehot, 'ce')\n",
    "temperature_ensemble, weights_ensemble = ets_calibrate(logits.numpy(),targs_onehot, n_classes, 'ce')\n",
    "isotonic_regression = mir_calibrate(logits.numpy(), targs_onehot)\n",
    "list_ir = irova_calibrate(logits.numpy(), targs_onehot)\n",
    "t_irovats, list_irovats = irovats_calibrate(logits.numpy(), targs_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d9087-0b26-4124-810f-da8b5d39073f",
   "metadata": {},
   "source": [
    "#### Calculate parameters of baseline methods on the perturbated validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa122b-a141-4fb1-874d-61d8c6baa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = estimateEpsilon(learn, df_train, imgSize, n_classes)\n",
    "logits_p, targs_p = getLogitsCVPR(learn,df_train,imgSize,epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbfd9f1-bc7d-46e9-bd12-93e2041f3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "targs_onehot_p = np.eye(n_classes)[targs_p.numpy()].astype(int)\n",
    "temperature_p = ts_calibrate(logits_p.numpy(), targs_onehot_p, 'ce')\n",
    "temperature_ensemble_p, weights_ensemble_p = ets_calibrate(logits_p.numpy(),targs_onehot_p, n_classes, 'ce')\n",
    "isotonic_regression_p = mir_calibrate(logits_p.numpy().astype('float32'), targs_onehot_p)\n",
    "list_ir_p = irova_calibrate(logits_p.numpy(), targs_onehot_p)\n",
    "t_irovats_p, list_irovats_p = irovats_calibrate(logits_p.numpy(), targs_onehot_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ac9a3-f000-4a48-9ab4-ced30548cb41",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Store experimental results in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10058dac-5948-46d0-b939-43f68868499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = path2 +  \"csv/\" + dataset + model + \"_\" + str(n_bins) + \"_\" + str(mult_val) + \"_\" + str(mult_test) + \".csv\"\n",
    "if os.path.exists(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "else:\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ee436-1d16-4ee1-844b-0d2d4d9a2f38",
   "metadata": {},
   "source": [
    "### Evaluation on CIFAR-C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4d445-5014-444b-b0e7-f653084850fb",
   "metadata": {},
   "source": [
    "#### Set experimental parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4dab1-6684-4429-83f9-b54234b87fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corruptions = ['Gaussian Noise', 'Shot Noise', 'Impulse Noise', 'Defocus Blur', 'Glass Blur', 'Motion Blur', 'Zoom Blur', \\\n",
    "               'Snow', 'Fog', 'Frost', 'Brightness', 'Contrast', 'Elastic', 'Pixelate', 'JPEG', 'Speckle Noise', \\\n",
    "               'Gaussian Blur', 'Spatter', 'Saturate']\n",
    "\n",
    "severity = list(range(1,6))\n",
    "\n",
    "vocabular = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "comb_cor_sev = list(itertools.product(corruptions, severity))\n",
    "\n",
    "calibration_methods = [\"None\", \"ts\", \"ets\", \"mir\", \"irova\", \"irovats\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8eeb4-519d-4269-bd70-f807e939810e",
   "metadata": {},
   "source": [
    "#### Calculate results on original CIFAR data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f5de8-9e1b-4c5e-92f8-3160e3e2d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"cifar10\":\n",
    "    df_test = pd.read_csv(path1 + \"data/cifar10/cifar10_TrainTestSplit.csv\")\n",
    "    df_test[\"fn\"] = [path1 + \"data/cifar10/\" + x for x in df_test[\"fn\"].values]\n",
    "if dataset == \"cifar100\":\n",
    "    df_test = pd.read_csv(path1 + \"data/cifar100/cifar100_TrainTestSplit.csv\")\n",
    "    df_test[\"fn\"] = [path1 + \"data/\" + x for x in df_test[\"fn\"].values]\n",
    "\n",
    "block = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "          get_x=ColReader(\"fn\"),\n",
    "          get_y=ColReader(\"label\"), \n",
    "          splitter=ColSplitter(col=\"valid\"),\n",
    "          item_tfms = [Resize(imgSize)],\n",
    "          batch_tfms = [*aug_transforms(mult = mult_test), Normalize.from_stats(*imagenet_stats)])\n",
    "\n",
    "dls = dblock.dataloaders(df_test, bs=bs, num_workers=3)\n",
    "learn.dls = dls\n",
    "set_seed(dls)\n",
    "\n",
    "for ttaugmented in [False, True]:\n",
    "    if ttaugmented:\n",
    "        hook = AggregatingHook(\n",
    "        m = learn.model[1][8],\n",
    "        hook_func = lambda m,i,o: o,\n",
    "        cpu = True\n",
    "        )\n",
    "\n",
    "        preds, targs = learn.tta()\n",
    "        logits = torch.cat(hook.stored)\n",
    "        logits = torch.reshape(logits,(5,df_test.valid.sum(),n_classes))\n",
    "        logits = sum(logits,0)/5\n",
    "\n",
    "    else:\n",
    "        hook = AggregatingHook(\n",
    "        m = learn.model[1][8],\n",
    "        hook_func = lambda m,i,o: o,\n",
    "        cpu = True\n",
    "        )\n",
    "\n",
    "        preds, targs = learn.get_preds()\n",
    "        logits = torch.cat(hook.stored)\n",
    "\n",
    "    for perturbed in [False, True]:\n",
    "        if not perturbed:\n",
    "            for calibration_method in calibration_methods:\n",
    "                if calibration_method == \"None\":\n",
    "                    preds_transformed = preds\n",
    "\n",
    "                if calibration_method == \"ts\":\n",
    "                    preds_transformed = ts_predict(logits.numpy(),temperature)\n",
    "\n",
    "                if calibration_method == \"ets\":\n",
    "                    preds_transformed = ets_predict(logits.numpy(),temperature_ensemble, weights_ensemble, n_classes)\n",
    "\n",
    "                if calibration_method == \"mir\":\n",
    "                    preds_transformed = mir_predict(logits.numpy(),isotonic_regression)\n",
    "\n",
    "                if calibration_method == \"irova\":\n",
    "                    preds_transformed = irova_predict(logits.numpy(),list_ir)\n",
    "                \n",
    "                if calibration_method == \"irovats\":\n",
    "                    preds_transformed = irovats_predict(logits.numpy(),temperature, list_ir)\n",
    "                \n",
    "                cal = calibration(preds_transformed, targs, n_bins)\n",
    "                ece = cal[\"ece\"]\n",
    "                nloss, brier = get_other_scores(preds_transformed.numpy(), targs.numpy())\n",
    "                mce = cal[\"mce\"]\n",
    "                acc = float(accuracy(preds,targs))\n",
    "                \n",
    "                to_append = pd.DataFrame({\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"TestSet\": \"Base\",\n",
    "                    \"calib\": calibration_method,\n",
    "                    \"pertubed\": perturbed,\n",
    "                    \"ttaugmented\": ttaugmented,\n",
    "                    \"n_bins\": n_bins,\n",
    "                    \"mult_val\": mult_val,\n",
    "                    \"mult_test\": mult_test,\n",
    "                    \"accuracy\": acc,\n",
    "                    \"ece\": ece,\n",
    "                    \"mce\": mce,\n",
    "                    \"brier\": brier,\n",
    "                    \"nll\": nloss\n",
    "                }, index = [5] )\n",
    "                df = pd.concat([df, to_append],ignore_index=True)\n",
    "        else:\n",
    "            for calibration_method in calibration_methods:   \n",
    "                if calibration_method == \"None\":\n",
    "                    preds_transformed = preds\n",
    "\n",
    "                if calibration_method == \"ts\":\n",
    "                    preds_transformed = ts_predict(logits.numpy(),temperature_p)\n",
    "\n",
    "                if calibration_method == \"ets\":\n",
    "                    preds_transformed = ets_predict(logits.numpy(),temperature_ensemble_p, weights_ensemble_p, n_classes)\n",
    "\n",
    "                if calibration_method == \"mir\":\n",
    "                    preds_transformed = mir_predict(logits.numpy(),isotonic_regression_p)\n",
    "\n",
    "                if calibration_method == \"irova\":\n",
    "                    preds_transformed = irova_predict(logits.numpy(),list_ir_p)\n",
    "                \n",
    "                if calibration_method == \"irovats\":\n",
    "                    preds_transformed = irovats_predict(logits.numpy(),temperature_p, list_ir_p)\n",
    "                \n",
    "\n",
    "                cal = calibration(preds_transformed, targs, n_bins)\n",
    "                ece = cal[\"ece\"]\n",
    "                mce = cal[\"mce\"]\n",
    "                nloss, brier = get_other_scores(preds_transformed.numpy(), targs.numpy())\n",
    "                \n",
    "                acc = float(accuracy(preds,targs))\n",
    "                to_append = pd.DataFrame({\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"TestSet\": \"Base\",\n",
    "                    \"calib\": calibration_method,\n",
    "                    \"pertubed\": perturbed,\n",
    "                    \"ttaugmented\": ttaugmented,\n",
    "                    \"n_bins\": n_bins,\n",
    "                    \"mult_val\": mult_val,\n",
    "                    \"mult_test\": mult_test,\n",
    "                    \"accuracy\": acc,\n",
    "                    \"ece\": ece,\n",
    "                    \"mce\": mce,\n",
    "                    \"brier\": brier,\n",
    "                    \"nll\":nloss\n",
    "                }, index = [5] )\n",
    "                df = pd.concat([df, to_append],ignore_index=True)\n",
    "df.to_csv(path2 + \"csv/\" + dataset + model + \"_\" + str(n_bins) + \"_\" + str(mult_val) + \"_\" + str(mult_test) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfcd009-91f2-4731-8bf8-0318693e890e",
   "metadata": {},
   "source": [
    "#### Calculate results on CIFAR with perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c16e26-08a8-49c6-9e8e-ccbf5132d216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in comb_cor_sev:\n",
    "    \n",
    "    if len(df) != 0 and (i[0] + \"_severity_\" + str(i[1])) in df.TestSet.values:\n",
    "        print(i[0] + \"_severity_\" + str(i[1]))\n",
    "        continue\n",
    "    \n",
    "    path = \"data/\" + dataset + \"-c/\"\n",
    "    path = path1 + path + i[0] + \"_severity_\" + str(i[1])\n",
    "    print(path)\n",
    "    labels = []\n",
    "    fname = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path): \n",
    "        for j in files:\n",
    "            if  dataset == \"cifar100\":\n",
    "                if j.split(\".\")[1] == \"jpg\":\n",
    "                    if len(j.split(\"_\")) == 2:\n",
    "                        labels.append(j.split(\"_\")[0])\n",
    "                        fname.append(str(path) +\"/\" + j)\n",
    "                    else:\n",
    "                        labels.append(j.split(\"_\")[0] + \"_\" + j.split(\"_\")[1])\n",
    "                        fname.append(str(path) +\"/\" + j)\n",
    "            if dataset == \"cifar10\":\n",
    "                if j.split(\".\")[1] == \"jpg\":\n",
    "                    labels.append(vocabular[int(j.split(\"_\")[0])])\n",
    "                    fname.append(str(path) +\"/\" + j)\n",
    "\n",
    "    test_dict = {\"fn\": fname, \"label\": labels}\n",
    "    \n",
    "    df_test = pd.DataFrame(test_dict)\n",
    "    df_test[\"valid\"] = 1\n",
    "    df_temp = df_train\n",
    "    df_temp[\"valid\"] = 0\n",
    "    df_test = df_test.append(df_temp)\n",
    "    \n",
    "    block = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "              get_x=ColReader(\"fn\"),\n",
    "              get_y=ColReader(\"label\"), \n",
    "              splitter=ColSplitter(col=\"valid\"),\n",
    "              item_tfms = [Resize(imgSize)],\n",
    "              batch_tfms = [*aug_transforms(mult = mult_test), Normalize.from_stats(*imagenet_stats)])\n",
    "              \n",
    "    dls = dblock.dataloaders(df_test, bs=bs, num_workers=3)\n",
    "    learn.dls = dls\n",
    "    set_seed(dls)\n",
    "    \n",
    "    for ttaugmented in [True, False]:\n",
    "        if ttaugmented:\n",
    "            hook = AggregatingHook(\n",
    "            m = learn.model[1][8],\n",
    "            hook_func = lambda m,i,o: o,\n",
    "            cpu = True\n",
    "            )\n",
    "\n",
    "            preds, targs = learn.tta()\n",
    "            logits = torch.cat(hook.stored)\n",
    "            logits = torch.reshape(logits,(5,df_test.valid.sum(),n_classes))\n",
    "            logits = sum(logits,0)/5\n",
    "\n",
    "        else:\n",
    "            hook = AggregatingHook(\n",
    "            m = learn.model[1][8],\n",
    "            hook_func = lambda m,i,o: o,\n",
    "            cpu = True\n",
    "            )\n",
    "\n",
    "            preds, targs = learn.get_preds()\n",
    "            logits = torch.cat(hook.stored)\n",
    "\n",
    "        for perturbed in [True, False]:\n",
    "            if not perturbed:\n",
    "                for calibration_method in calibration_methods:\n",
    "                    if calibration_method == \"None\":\n",
    "                        preds_transformed = preds\n",
    "\n",
    "                    if calibration_method == \"ts\":\n",
    "                        preds_transformed = ts_predict(logits.numpy(),temperature)\n",
    "\n",
    "                    if calibration_method == \"ets\":\n",
    "                        preds_transformed = ets_predict(logits.numpy(),temperature_ensemble, weights_ensemble, n_classes)\n",
    "\n",
    "                    if calibration_method == \"mir\":\n",
    "                        preds_transformed = mir_predict(logits.numpy(),isotonic_regression)\n",
    "\n",
    "                    if calibration_method == \"irova\":\n",
    "                        preds_transformed = irova_predict(logits.numpy(),list_ir)\n",
    "\n",
    "                    if calibration_method == \"irovats\":\n",
    "                        preds_transformed = irovats_predict(logits.numpy(),temperature, list_ir)\n",
    "\n",
    "                    cal = calibration(preds_transformed, targs, n_bins)\n",
    "                    ece = cal[\"ece\"]\n",
    "                    mce = cal[\"mce\"]\n",
    "                    nloss, brier = get_other_scores(preds_transformed.numpy(), targs.numpy())\n",
    "                    acc = float(accuracy(preds,targs))\n",
    "                    to_append = pd.DataFrame({\n",
    "                        \"model\": model,\n",
    "                        \"dataset\": dataset,\n",
    "                        \"TestSet\": i[0] + \"_severity_\" + str(i[1]),\n",
    "                        \"calib\": calibration_method,\n",
    "                        \"pertubed\": perturbed,\n",
    "                        \"ttaugmented\": ttaugmented,\n",
    "                        \"n_bins\": n_bins,\n",
    "                        \"mult_val\": mult_val,\n",
    "                        \"mult_test\": mult_test,\n",
    "                        \"accuracy\": acc,\n",
    "                        \"ece\": ece,\n",
    "                        \"mce\": mce,\n",
    "                        \"brier\": brier,\n",
    "                        \"nll\": nloss\n",
    "                    }, index = [5] )\n",
    "                    df = pd.concat([df, to_append],ignore_index=True)\n",
    "            else:\n",
    "                for calibration_method in calibration_methods:   \n",
    "                    if calibration_method == \"None\":\n",
    "                        preds_transformed = preds\n",
    "\n",
    "                    if calibration_method == \"ts\":\n",
    "                        preds_transformed = ts_predict(logits.numpy(),temperature_p)\n",
    "\n",
    "                    if calibration_method == \"ets\":\n",
    "                        preds_transformed = ets_predict(logits.numpy(),temperature_ensemble_p, weights_ensemble_p, n_classes)\n",
    "\n",
    "                    if calibration_method == \"mir\":\n",
    "                        preds_transformed = mir_predict(logits.numpy(),isotonic_regression_p)\n",
    "\n",
    "                    if calibration_method == \"irova\":\n",
    "                        preds_transformed = irova_predict(logits.numpy(),list_ir_p)\n",
    "\n",
    "                    if calibration_method == \"irovats\":\n",
    "                        preds_transformed = irovats_predict(logits.numpy(),temperature_p, list_ir_p)\n",
    "\n",
    "\n",
    "                    cal = calibration(preds_transformed, targs, n_bins)\n",
    "                    ece = cal[\"ece\"]\n",
    "                    mce = cal[\"mce\"]\n",
    "                    nloss, brier = get_other_scores(preds.numpy(), targs.numpy())\n",
    "                    acc = float(accuracy(preds,targs))\n",
    "                    to_append = pd.DataFrame({\n",
    "                        \"model\": model,\n",
    "                        \"dataset\": dataset,\n",
    "                        \"TestSet\": i[0] + \"_severity_\" + str(i[1]),\n",
    "                        \"calib\": calibration_method,\n",
    "                        \"pertubed\": perturbed,\n",
    "                        \"ttaugmented\": ttaugmented,\n",
    "                        \"n_bins\": n_bins,\n",
    "                        \"mult_val\": mult_val,\n",
    "                        \"mult_test\": mult_test,\n",
    "                        \"accuracy\": acc,\n",
    "                        \"ece\": ece,\n",
    "                        \"mce\": mce,\n",
    "                        \"brier\": brier,\n",
    "                        \"nll\": nloss\n",
    "                    }, index = [5] )\n",
    "                    df = pd.concat([df, to_append],ignore_index=True)\n",
    "\n",
    "        df.to_csv(path2 + \"csv/\" + dataset + model + \"_\" + str(n_bins) + \"_\" + str(mult_val) + \"_\" + str(mult_test) + \".csv\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c43fe-07a3-4f6e-88f6-ca5978a0f1c0",
   "metadata": {},
   "source": [
    "### Evaluation on Skin Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e957190-6ba8-4995-a548-fc093aa070bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsets = [\"ID\", \"Sidney\",\"MSK2020\"]\n",
    "\n",
    "for testset in testsets:\n",
    "    if testset == \"ID\":\n",
    "        df_test = pd.read_csv(path1 + \"data/skin_new/skin_TrainIDTestSplit.csv\")\n",
    "        df_test[\"fn\"] = [path1 + x for x in df_test[\"fn\"].values]\n",
    "        df_test = df_test[[\"fn\",\"label\",\"valid\"]]\n",
    "    if testset == \"Sidney\":\n",
    "        df_test = pd.read_csv(path1 + \"data/skin_new/skin_TrainISIC2020_SIDNEYSplit.csv\")\n",
    "        df_test[\"fn\"] = [path1 + x for x in df_test[\"fn\"].values]\n",
    "        df_test = df_test[[\"fn\",\"label\",\"valid\"]]\n",
    "    if testset == \"MSK2020\":\n",
    "        df_test = pd.read_csv(path1 + \"data/skin_new/skin_TrainISIC2020_MSKCCSplit.csv\")\n",
    "        df_test[\"fn\"] = [path1 + x for x in df_test[\"fn\"].values]\n",
    "        df_test = df_test[[\"fn\",\"label\",\"valid\"]]\n",
    "    \n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "              get_x=ColReader(\"fn\"),\n",
    "              get_y=ColReader(\"label\"), \n",
    "              splitter=ColSplitter(col=\"valid\"),\n",
    "              item_tfms = [Resize(imgSize)],\n",
    "              batch_tfms = [*aug_transforms(), Normalize.from_stats(*imagenet_stats)])\n",
    "              \n",
    "    dls = dblock.dataloaders(df_test, bs=bs, num_workers=3)\n",
    "    learn.dls = dls\n",
    "    set_seed(dls)\n",
    "\n",
    "    for ttaugmented in [False, True]:\n",
    "        if ttaugmented:\n",
    "            hook = AggregatingHook(\n",
    "            m = learn.model[1][8],\n",
    "            hook_func = lambda m,i,o: o,\n",
    "            cpu = True\n",
    "            )\n",
    "\n",
    "            preds, targs = learn.tta()\n",
    "            logits = torch.cat(hook.stored)\n",
    "            logits = torch.reshape(logits,(5,df_test.valid.sum(),n_classes))\n",
    "            logits = sum(logits,0)/5\n",
    "\n",
    "        else:\n",
    "            hook = AggregatingHook(\n",
    "            m = learn.model[1][8],\n",
    "            hook_func = lambda m,i,o: o,\n",
    "            cpu = True\n",
    "            )\n",
    "\n",
    "            preds, targs = learn.get_preds()\n",
    "            logits = torch.cat(hook.stored)\n",
    "\n",
    "        for perturbed in [False, True]:\n",
    "            if not perturbed:\n",
    "                for calibration_method in calibration_methods:\n",
    "                    if calibration_method == \"None\":\n",
    "                        preds_transformed = preds\n",
    "\n",
    "                    if calibration_method == \"ts\":\n",
    "                        preds_transformed = ts_predict(logits.numpy(),temperature)\n",
    "\n",
    "                    if calibration_method == \"ets\":\n",
    "                        preds_transformed = ets_predict(logits.numpy(),temperature_ensemble, weights_ensemble, n_classes)\n",
    "\n",
    "                    if calibration_method == \"mir\":\n",
    "                        preds_transformed = mir_predict(logits.numpy(),isotonic_regression)\n",
    "\n",
    "                    if calibration_method == \"irova\":\n",
    "                        preds_transformed = irova_predict(logits.numpy(),list_ir)\n",
    "\n",
    "                    if calibration_method == \"irovats\":\n",
    "                        preds_transformed = irovats_predict(logits.numpy(),temperature, list_ir)\n",
    "\n",
    "                    cal = calibration(preds_transformed, targs, n_bins)\n",
    "                    ece = cal[\"ece\"]\n",
    "                    nloss, brier = get_other_scores(preds_transformed.numpy(), targs.numpy())\n",
    "                    mce = cal[\"mce\"]\n",
    "                    acc = float(balanced_accuracy_score(targs,torch.argmax(preds,dim=1)))\n",
    "\n",
    "                    to_append = pd.DataFrame({\n",
    "                        \"model\": model,\n",
    "                        \"dataset\": dataset,\n",
    "                        \"TestSet\": testset,\n",
    "                        \"calib\": calibration_method,\n",
    "                        \"pertubed\": perturbed,\n",
    "                        \"ttaugmented\": ttaugmented,\n",
    "                        \"n_bins\": n_bins,\n",
    "                        \"mult_val\": mult_val,\n",
    "                        \"mult_test\": mult_test,\n",
    "                        \"accuracy\": acc,\n",
    "                        \"ece\": ece,\n",
    "                        \"brier\": brier,\n",
    "                        \"nll\": nloss,\n",
    "                        \"mce\": mce\n",
    "                    }, index = [5] )\n",
    "                    df = pd.concat([df, to_append],ignore_index=True)\n",
    "            else:\n",
    "                for calibration_method in calibration_methods:   \n",
    "                    if calibration_method == \"None\":\n",
    "                        preds_transformed = preds\n",
    "\n",
    "                    if calibration_method == \"ts\":\n",
    "                        preds_transformed = ts_predict(logits.numpy(),temperature_p)\n",
    "\n",
    "                    if calibration_method == \"ets\":\n",
    "                        preds_transformed = ets_predict(logits.numpy(),temperature_ensemble_p, weights_ensemble_p, n_classes)\n",
    "\n",
    "                    if calibration_method == \"mir\":\n",
    "                        preds_transformed = mir_predict(logits.numpy(),isotonic_regression_p)\n",
    "\n",
    "                    if calibration_method == \"irova\":\n",
    "                        preds_transformed = irova_predict(logits.numpy(),list_ir_p)\n",
    "\n",
    "                    if calibration_method == \"irovats\":\n",
    "                        preds_transformed = irovats_predict(logits.numpy(),temperature_p, list_ir_p)\n",
    "\n",
    "\n",
    "                    cal = calibration(preds_transformed, targs, n_bins)\n",
    "                    ece = cal[\"ece\"]\n",
    "                    nloss, brier = get_other_scores(preds_transformed.numpy(), targs.numpy())\n",
    "                    mce = cal[\"mce\"]\n",
    "                    acc = float(balanced_accuracy_score(targs,torch.argmax(preds,dim=1)))\n",
    "                    to_append = pd.DataFrame({\n",
    "                        \"model\": model,\n",
    "                        \"dataset\": dataset,\n",
    "                        \"TestSet\": testset,\n",
    "                        \"calib\": calibration_method,\n",
    "                        \"pertubed\": perturbed,\n",
    "                        \"ttaugmented\": ttaugmented,\n",
    "                        \"n_bins\": n_bins,\n",
    "                        \"mult_val\": mult_val,\n",
    "                        \"mult_test\": mult_test,\n",
    "                        \"accuracy\": acc,\n",
    "                        \"ece\": ece,\n",
    "                        \"brier\": brier,\n",
    "                        \"nll\": nloss,\n",
    "                        \"mce\": mce\n",
    "                    }, index = [5] )\n",
    "                    df = pd.concat([df, to_append],ignore_index=True)\n",
    "df.to_csv(path2 + \"csv/\" + dataset + model + \"_\" + str(n_bins) + \"_\" + str(mult_val) + \"_\" + str(mult_test) + \"_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
